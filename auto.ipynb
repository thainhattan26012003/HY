{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dropout, Dense, Flatten, Attention, Layer, Concatenate, Permute, Reshape, Multiply, UpSampling1D, AveragePooling1D, Input\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "import warnings\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from pmdarima import auto_arima\n",
    "import keras.backend as K\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from lssvm import LSSVR\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(a,b,c,d,e,f,g):\n",
    "    current_time = datetime.now()\n",
    "    data = {\n",
    "        'model' : [g],\n",
    "        'sim' : [a],\n",
    "        'mae' : [b],\n",
    "        'rmse' : [c],\n",
    "        'fsd' : [d],\n",
    "        'R' : [e],\n",
    "        'NSE': [f],\n",
    "        'time' : [current_time]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    with open('results_combine.csv', 'a', newline='') as f:\n",
    "        if os.path.isfile('results_combine.csv'):\n",
    "            df.to_csv('results_combine.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv('results_combine.csv', index=False)\n",
    "\n",
    "def to_df(data_list):\n",
    "    X_df = [i[:-1] for i in data_list]\n",
    "    y_df = [i[-1] for i in data_list]\n",
    "    transposed_lists = [list(x) for x in zip(*X_df)]\n",
    "\n",
    "    df_list = pd.DataFrame({f'Column{i+1}': lst for i, lst in enumerate(transposed_lists)})\n",
    "    df_list['Target'] = y_df\n",
    "    return df_list\n",
    "\n",
    "def transform_to_multivariate(data, T):\n",
    "    M = []\n",
    "    for i in range(len(data) - T):\n",
    "        row = data[i:i + T + 1]\n",
    "        M.append(row)\n",
    "    return np.array(M)\n",
    "\n",
    "def calculate_similarity(value_lst_after, value_lst_before):\n",
    "        T = len(value_lst_after)  # Number of missing values\n",
    "        similarity_sum = 0\n",
    "\n",
    "        for i in range(T):\n",
    "            yi = value_lst_after[i]\n",
    "            xi = value_lst_before[i]\n",
    "            similarity_sum += 1 / (1 + abs(yi - xi) / (max(value_lst_before) - min(value_lst_before)))\n",
    "\n",
    "        similarity = similarity_sum / T\n",
    "        return similarity\n",
    "\n",
    "def calculate_MAE(value_lst_missing, value_lst_after):\n",
    "        return mean_absolute_error(value_lst_missing, value_lst_after)\n",
    "\n",
    "def calculate_RMSE(value_lst_missing, value_lst_after):\n",
    "    return np.sqrt(mean_squared_error(value_lst_missing, value_lst_after))\n",
    "\n",
    "def calculate_FB(value_lst_missing, value_lst_after):\n",
    "    return 2 * abs((np.mean(value_lst_after) - np.mean(value_lst_missing)) / (np.mean(value_lst_after) + np.mean(value_lst_missing)))\n",
    "\n",
    "def calculate_fsd(value_lst_missing, value_lst_after):\n",
    "    std_dev_Y = np.std(value_lst_after)\n",
    "    std_dev_X = np.std(value_lst_missing)\n",
    "\n",
    "    if std_dev_X == 0:\n",
    "        return None\n",
    "    \n",
    "    fsd = 2 * abs((std_dev_Y - std_dev_X) / (std_dev_X + std_dev_Y))\n",
    "    \n",
    "    return fsd\n",
    "\n",
    "def calculate_r_score(value_lst_missing, value_lst_after):\n",
    "\n",
    "    correlation_matrix = np.corrcoef(value_lst_missing, value_lst_after)\n",
    "    r_score = correlation_matrix[0, 1]\n",
    "    return r_score\n",
    "\n",
    "def calculate_nse(value_lst_missing, value_lst_after):\n",
    "\n",
    "    value_lst_missing = np.array(value_lst_missing)\n",
    "    value_lst_after = np.array(value_lst_after)\n",
    "\n",
    "    numerator = np.sum((value_lst_missing - value_lst_after)**2)\n",
    "    denominator = np.sum((value_lst_missing - np.mean(value_lst_missing))**2)\n",
    "\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    \n",
    "    return nse\n",
    "\n",
    "\n",
    "def calculate_metrics_for_Auto_CNN(value_lst_after,name_model):\n",
    "    \n",
    "    df_before_missing = pd.read_csv('waterlevel.csv')\n",
    "    value_lst_missing = df_before_missing['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap]\n",
    "\n",
    "\n",
    "    similarity_score = calculate_similarity(value_lst_after, value_lst_missing)\n",
    "    MAE_score = calculate_MAE(value_lst_missing, value_lst_after)\n",
    "    RMSE_score = calculate_RMSE(value_lst_missing, value_lst_after)\n",
    "    FSD_score = calculate_fsd(value_lst_missing, value_lst_after)\n",
    "    R_score = calculate_r_score(value_lst_missing, value_lst_after)\n",
    "    NSE_score = calculate_nse(value_lst_missing, value_lst_after)\n",
    "    \n",
    "    sim_lst_Auto_CNN.append(similarity_score)\n",
    "    mae_lst_Auto_CNN.append(MAE_score)\n",
    "    rmse_lst_Auto_CNN.append(RMSE_score)\n",
    "    fsd_lst_Auto_CNN.append(FSD_score)\n",
    "    r_lst_Auto_CNN.append(R_score)\n",
    "    nse_lst_Auto_CNN.append(NSE_score)\n",
    "\n",
    "    \n",
    "    print('\\nOri_data:', value_lst_missing)\n",
    "    print('\\nvalue_data:', value_lst_after)\n",
    "    print('\\nSimilarity_score:', similarity_score)\n",
    "    print('\\nMean Absolute Error (MAE):', MAE_score)\n",
    "    print('\\nRoot Mean Squared Error (RMSE):', RMSE_score)\n",
    "    print('\\nFraction of Standard Deviation Score:', FSD_score)\n",
    "    print('\\nR score:', R_score)\n",
    "    print('\\nThe Nash Sutcliffe efficiency (NSE):', NSE_score)\n",
    "\n",
    "    results(similarity_score, MAE_score, RMSE_score, FSD_score, R_score, NSE_score,name_model)\n",
    "\n",
    "def create_continuous_missing_values(dataframe, column_name, num_missing_values):\n",
    "    modified_df = dataframe.copy()\n",
    "    \n",
    "    if len(dataframe) > num_missing_values:\n",
    "        random_index = random.randint(0, len(dataframe) - num_missing_values)\n",
    "        modified_df.loc[random_index:random_index + num_missing_values - 1, column_name] = np.nan\n",
    "    else:\n",
    "        print(\"Error: The number of missing values requested exceeds the DataFrame's capacity.\")\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "sim_lst_Auto_CNN = []\n",
    "mae_lst_Auto_CNN = []\n",
    "rmse_lst_Auto_CNN = []\n",
    "fsd_lst_Auto_CNN = []\n",
    "r_lst_Auto_CNN = []\n",
    "nse_lst_Auto_CNN = []\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def auto_encoder(input_shape):\n",
    "    auto = tf.keras.models.Sequential()\n",
    "    \n",
    "    # model = Sequential()\n",
    "    auto.add(Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=input_shape))\n",
    "    auto.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    auto.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    auto.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "    # Decoder\n",
    "    auto.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(UpSampling1D(size=2))\n",
    "    auto.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(UpSampling1D(size=2))\n",
    "    auto.add(Conv1D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(UpSampling1D(size=2))\n",
    "    auto.add(Conv1D(1, kernel_size=3, activation='relu', padding='same'))\n",
    "    \n",
    "    auto.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return auto\n",
    "\n",
    "\n",
    "def create_combined_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Autoencoder layers\n",
    "    model.add(auto_encoder(input_shape))\n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encoder(input_shape):\n",
    "    auto = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    auto.add(Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=input_shape))\n",
    "    auto.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    auto.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    auto.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "    # Decoder\n",
    "    auto.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(UpSampling1D(size=2))\n",
    "    auto.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(UpSampling1D(size=2))\n",
    "    auto.add(Conv1D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "    auto.add(UpSampling1D(size=2))\n",
    "    auto.add(Conv1D(1, kernel_size=3, activation='sigmoid', padding='same'))  # Use sigmoid for values between 0 and 1\n",
    "    # auto.add(Flatten())\n",
    "    \n",
    "    # auto.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return auto\n",
    "\n",
    "def create_combined_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Autoencoder layers\n",
    "    model.add(auto_encoder(input_shape))\n",
    "\n",
    "    # Adding extra CNN layers\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Conv1D(filters=512, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "\n",
      "All values in df_miss is in the first !!!\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "for i in range(0, 12):\n",
    "    \n",
    "    filename = f'waterlevel_missing_{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for i, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = i\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "        \n",
    "        # Calculate for Auto_CNN \n",
    "        first_value_Auto_CNN = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_Auto_CNN)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_Auto_CNN(X)        \n",
    "        # model.fit(X, y, epochs=500, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        # model = auto_encoder((X.shape[1], 1))\n",
    "        # print(model.output)\n",
    "        # model.fit(X, X , epochs=50, batch_size = 16)\n",
    "\n",
    "        combined_model = create_combined_model((X.shape[1], 1))\n",
    "        combined_model.fit(X, X, epochs=50, batch_size=64)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_Auto_CNN = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = combined_model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_Auto_CNN.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of Auto_CNN only (first):')                        #  \n",
    "        calculate_metrics_for_Auto_CNN(results_first_Auto_CNN,'results_Auto_CNN (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_Auto_CNN, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_Auto_CNN = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_Auto_CNN)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_Auto_CNN(X)\n",
    "        # model.fit(X, y, epochs=500, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        # model = model_Auto_CNN(X)\n",
    "        # model.fit(X, y, epochs=50, batch_size=64)\n",
    "        combined_model = create_combined_model((X.shape[1], 1))\n",
    "        combined_model.fit(X, X, epochs=50, batch_size=64)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_Auto_CNN = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            # data_last[size_of_gap] = float(model.predict(np.array(data_last[:size_of_gap]).reshape(1,-1)).ravel()[0])\n",
    "            data_last[size_of_gap] = combined_model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_Auto_CNN.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of Auto_CNN only (last):')                       #\n",
    "        calculate_metrics_for_Auto_CNN(results_last_Auto_CNN,'results_Auto_CNN (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_Auto_CNN, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        # X_MDa_train = X_MDa_train.reshape((X_MDa_train.shape[0], X_MDa_train.shape[1], 1))\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        # model_MDa, callbacks_MDa = model_Auto_CNN(X_MDa_train)\n",
    "        # model_MDa.fit(X_MDa_train, y_MDa_train, epochs=500, batch_size = 64, callbacks=callbacks_MDa)\n",
    "        \n",
    "        # model_MDa = model_Auto_CNN(X_MDa_train)\n",
    "        # model_MDa.fit(X_MDa_train, y_MDa_train, epochs=50, batch_size=64)\n",
    "\n",
    "        combined_model_MDa = create_combined_model((X_MDa_train.shape[1], 1))\n",
    "        combined_model_MDa.fit(X_MDa_train, X_MDa_train, epochs=50, batch_size=64)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = combined_model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        # X_MDb_train = X_MDb_train.reshape((X_MDb_train.shape[0], X_MDb_train.shape[1], 1))\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        # model_MDb, callbacks_MDb = model_Auto_CNN(X_MDb_train)\n",
    "        # model_MDb.fit(X_MDb_train, y_MDb_train, epochs=500, batch_size = 64, callbacks=callbacks_MDb)\n",
    "        \n",
    "        # model_MDb = model_Auto_CNN(X_MDb_train)\n",
    "        # model_MDb.fit(X_MDb_train, y_MDb_train, epochs=50, batch_size=64)\n",
    "\n",
    "        combined_model_MDb = create_combined_model((X_MDb_train.shape[1], 1))\n",
    "        combined_model_MDb.fit(X_MDb_train, X_MDb_train, epochs=50, batch_size=64)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = combined_model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of Auto_CNN only: ')                                         #\n",
    "        results_Auto_CNN =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_Auto_CNN(results_Auto_CNN,'results_Auto_CNN (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_Auto_CNN, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "current_time = datetime.now()\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity Auto_CNN: ',np.mean(sim_lst_Auto_CNN))\n",
    "print('\\nMean of Mean Absoulute Error Auto_CNN :',np.mean(mae_lst_Auto_CNN))\n",
    "print('\\nMean of Root Mean Squared Error Auto_CNN: ',np.mean(rmse_lst_Auto_CNN))\n",
    "print('\\nMean of Fraction of Standard Deviation Auto_CNN: ',np.mean(fsd_lst_Auto_CNN)) \n",
    "print('\\nMean of R-score Auto_CNN: ', np.mean(r_lst_Auto_CNN))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_Auto_CNN))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
