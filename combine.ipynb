{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dropout, Dense, Layer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(a,b,c,d,e,f,g):\n",
    "    current_time = datetime.now()\n",
    "    data = {\n",
    "        'model' : [g],\n",
    "        'sim' : [a],\n",
    "        'mae' : [b],\n",
    "        'rmse' : [c],\n",
    "        'fsd' : [d],\n",
    "        'R' : [e],\n",
    "        'NSE': [f],\n",
    "        'time' : [current_time]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    with open('results_combine.csv', 'a', newline='') as f:\n",
    "        if os.path.isfile('results_combine.csv'):\n",
    "            df.to_csv('results_combine.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv('results_combine.csv', index=False)\n",
    "\n",
    "def to_df(data_list):\n",
    "    X_df = [i[:-1] for i in data_list]\n",
    "    y_df = [i[-1] for i in data_list]\n",
    "    transposed_lists = [list(x) for x in zip(*X_df)]\n",
    "\n",
    "    df_list = pd.DataFrame({f'Column{i+1}': lst for i, lst in enumerate(transposed_lists)})\n",
    "    df_list['Target'] = y_df\n",
    "    return df_list\n",
    "\n",
    "def transform_to_multivariate(data, T):\n",
    "    M = []\n",
    "    for i in range(len(data) - T):\n",
    "        row = data[i:i + T + 1]\n",
    "        M.append(row)\n",
    "    return np.array(M)\n",
    "\n",
    "def calculate_similarity(value_lst_after, value_lst_before):\n",
    "        T = len(value_lst_after)  # Number of missing values\n",
    "        similarity_sum = 0\n",
    "\n",
    "        for i in range(T):\n",
    "            yi = value_lst_after[i]\n",
    "            xi = value_lst_before[i]\n",
    "            similarity_sum += 1 / (1 + abs(yi - xi) / (max(value_lst_before) - min(value_lst_before)))\n",
    "\n",
    "        similarity = similarity_sum / T\n",
    "        return similarity\n",
    "\n",
    "def calculate_MAE(value_lst_missing, value_lst_after):\n",
    "        return mean_absolute_error(value_lst_missing, value_lst_after)\n",
    "\n",
    "def calculate_RMSE(value_lst_missing, value_lst_after):\n",
    "    return np.sqrt(mean_squared_error(value_lst_missing, value_lst_after))\n",
    "\n",
    "def calculate_FB(value_lst_missing, value_lst_after):\n",
    "    return 2 * abs((np.mean(value_lst_after) - np.mean(value_lst_missing)) / (np.mean(value_lst_after) + np.mean(value_lst_missing)))\n",
    "\n",
    "def calculate_fsd(value_lst_missing, value_lst_after):\n",
    "    std_dev_Y = np.std(value_lst_after)\n",
    "    std_dev_X = np.std(value_lst_missing)\n",
    "\n",
    "    if std_dev_X == 0:\n",
    "        return None\n",
    "    \n",
    "    fsd = 2 * abs((std_dev_Y - std_dev_X) / (std_dev_X + std_dev_Y))\n",
    "    \n",
    "    return fsd\n",
    "\n",
    "def calculate_r_score(value_lst_missing, value_lst_after):\n",
    "\n",
    "    correlation_matrix = np.corrcoef(value_lst_missing, value_lst_after)\n",
    "    r_score = correlation_matrix[0, 1]\n",
    "    return r_score\n",
    "\n",
    "def calculate_nse(value_lst_missing, value_lst_after):\n",
    "\n",
    "    value_lst_missing = np.array(value_lst_missing)\n",
    "    value_lst_after = np.array(value_lst_after)\n",
    "\n",
    "    numerator = np.sum((value_lst_missing - value_lst_after)**2)\n",
    "    denominator = np.sum((value_lst_missing - np.mean(value_lst_missing))**2)\n",
    "\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    \n",
    "    return nse\n",
    "\n",
    "def calculate_metrics_for_combine(value_lst_after,name_model):\n",
    "    \n",
    "    df_before_missing = pd.read_csv('waterlevel.csv')\n",
    "    value_lst_missing = df_before_missing['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap]\n",
    "\n",
    "\n",
    "    similarity_score = calculate_similarity(value_lst_after, value_lst_missing)\n",
    "    MAE_score = calculate_MAE(value_lst_missing, value_lst_after)\n",
    "    RMSE_score = calculate_RMSE(value_lst_missing, value_lst_after)\n",
    "    FSD_score = calculate_fsd(value_lst_missing, value_lst_after)\n",
    "    R_score = calculate_r_score(value_lst_missing, value_lst_after)\n",
    "    NSE_score = calculate_nse(value_lst_missing, value_lst_after)\n",
    "    \n",
    "    sim_lst_combine.append(similarity_score)\n",
    "    mae_lst_combine.append(MAE_score)\n",
    "    rmse_lst_combine.append(RMSE_score)\n",
    "    fsd_lst_combine.append(FSD_score)\n",
    "    r_lst_combine.append(R_score)\n",
    "    nse_lst_combine.append(NSE_score)\n",
    "\n",
    "    \n",
    "    print('\\nOri_data:', value_lst_missing)\n",
    "    print('\\nvalue_data:', value_lst_after)\n",
    "    print('\\nSimilarity_score:', similarity_score)\n",
    "    print('\\nMean Absolute Error (MAE):', MAE_score)\n",
    "    print('\\nRoot Mean Squared Error (RMSE):', RMSE_score)\n",
    "    print('\\nFraction of Standard Deviation Score:', FSD_score)\n",
    "    print('\\nR score:', R_score)\n",
    "    print('\\nThe Nash Sutcliffe efficiency (NSE):', NSE_score)\n",
    "\n",
    "    results(similarity_score, MAE_score, RMSE_score, FSD_score, R_score, NSE_score,name_model)\n",
    "\n",
    "def create_continuous_missing_values(dataframe, column_name, num_missing_values):\n",
    "    modified_df = dataframe.copy()\n",
    "    \n",
    "    if len(dataframe) > num_missing_values:\n",
    "        random_index = random.randint(0, len(dataframe) - num_missing_values)\n",
    "        modified_df.loc[random_index:random_index + num_missing_values - 1, column_name] = np.nan\n",
    "    else:\n",
    "        print(\"Error: The number of missing values requested exceeds the DataFrame's capacity.\")\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "sim_lst_combine = []\n",
    "mae_lst_combine = []\n",
    "rmse_lst_combine = []\n",
    "fsd_lst_combine = []\n",
    "r_lst_combine = []\n",
    "nse_lst_combine = []\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_df_path = 'waterlevel.csv'\n",
    "# try:\n",
    "#     original_df = pd.read_csv(original_df_path)\n",
    "    \n",
    "#     for i in range(0, 12):\n",
    "#         modified_df = create_continuous_missing_values(original_df, 'Waterlevel', 48)\n",
    "#         modified_df.to_csv(f'waterlevel_missing_test_{i}.csv', index=False)\n",
    "        \n",
    "#         print(f'waterlevel_missing_test_{i}.csv saved with continuous missing values.')\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Failed to find '{original_df_path}'. Please check the file path and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_combine(X_train):\n",
    "    combine = tf.keras.models.Sequential()\n",
    "\n",
    "    combine.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    combine.add(MaxPooling1D(pool_size=2))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "    combine.add(Dropout(0.15))\n",
    "\n",
    "    class Attention(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            super(Attention, self).__init__(**kwargs)\n",
    "    \n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1), \n",
    "                                     initializer='random_normal', trainable=True)\n",
    "            self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1), \n",
    "                                     initializer='zeros', trainable=True)        \n",
    "            super(Attention, self).build(input_shape)\n",
    "     \n",
    "        def call(self, x):\n",
    "            e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "            e = K.squeeze(e, axis=-1)\n",
    "            alpha = K.softmax(e)\n",
    "            alpha = K.expand_dims(alpha, axis=-1)\n",
    "            context = x * alpha\n",
    "            context = K.sum(context, axis=1)\n",
    "            return context\n",
    "\n",
    "    combine.add(Attention())\n",
    "    \n",
    "    combine.add(Dense(units=64, activation='relu'))\n",
    "    \n",
    "    combine.add(Dense(units=1))\n",
    "    \n",
    "    combine.compile(optimizer=Adam(), loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=16, callbacks (patience=30), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "\n",
    "for location in range(11,12):\n",
    "    \n",
    "    filename = f'waterlevel_missing/waterlevel_missing_{location}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for j, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = j\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "        first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of combine only (first):')                        #  \n",
    "        calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        folder_path = 'P:\\SU24\\Imputation\\HY_git\\\\128,256,512,64,64'\n",
    "        filename = f'128,256,512,64,64, Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2.png'\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        plt.savefig(full_path)\n",
    "        plt.show()\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_combine)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of combine only (last):')                       #\n",
    "        calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        folder_path = 'P:\\SU24\\Imputation\\HY_git\\\\128,256,512,64,64'\n",
    "        filename = f'128,256,512,64,64, Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2.png'\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        plt.savefig(full_path)\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        model_MDa = model_combine(X_MDa_train)\n",
    "        model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        model_MDb = model_combine(X_MDb_train)\n",
    "        model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of combine only: ')                                         #\n",
    "        results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()   \n",
    "        folder_path = 'P:\\SU24\\Imputation\\HY_git\\\\128,256,512,64,64'\n",
    "        filename = f'128,256,512,64,64, Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2.png'\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        plt.savefig(full_path)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "current_time = datetime.now()\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_combine(X_train):\n",
    "    combine = tf.keras.models.Sequential()\n",
    "\n",
    "    combine.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    combine.add(MaxPooling1D(pool_size=2))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "    combine.add(Dropout(0.15))\n",
    "\n",
    "    class Attention(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            super(Attention, self).__init__(**kwargs)\n",
    "    \n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1), \n",
    "                                     initializer='random_normal', trainable=True)\n",
    "            self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1), \n",
    "                                     initializer='zeros', trainable=True)        \n",
    "            super(Attention, self).build(input_shape)\n",
    "     \n",
    "        def call(self, x):\n",
    "            e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "            e = K.squeeze(e, axis=-1)\n",
    "            alpha = K.softmax(e)\n",
    "            alpha = K.expand_dims(alpha, axis=-1)\n",
    "            context = x * alpha\n",
    "            context = K.sum(context, axis=1)\n",
    "            return context\n",
    "\n",
    "    combine.add(Attention())\n",
    "    \n",
    "    combine.add(Dense(units=128, activation='relu'))\n",
    "    \n",
    "    combine.add(Dense(units=1))\n",
    "    \n",
    "    combine.compile(optimizer=Adam(), loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "\n",
    "for location in range(0,12):\n",
    "    \n",
    "    filename = f'waterlevel_missing/waterlevel_missing_{location}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for j, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = j\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "        first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of combine only (first):')                        #  \n",
    "        calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        folder_path = 'P:\\SU24\\Imputation\\HY_git\\HY\\\\128,256,512,128,128'\n",
    "        filename = f'128,256,512,128,128, Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2.png'\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        plt.savefig(full_path)\n",
    "        plt.show()\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_combine)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of combine only (last):')                       #\n",
    "        calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        folder_path = 'P:\\SU24\\Imputation\\HY_git\\HY\\\\128,256,512,128,128'\n",
    "        filename = f'128,256,512,128,128, Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2.png'\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        plt.savefig(full_path)\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        model_MDa = model_combine(X_MDa_train)\n",
    "        model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        model_MDb = model_combine(X_MDb_train)\n",
    "        model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of combine only: ')                                         #\n",
    "        results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()   \n",
    "        folder_path = 'P:\\SU24\\Imputation\\HY_git\\HY\\\\128,256,512,128,128'\n",
    "        filename = f'128,256,512,128,128, Missing {location}, epochs=200, batch_size=16, patience=30, validation_split=0.2.png'\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        plt.savefig(full_path)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "current_time = datetime.now()\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=8, callbacks (patience=30), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Missing {location}, epochs=200, batch_size=8, patience=30, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=8, patience=30, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Missing {location}, epochs=200, batch_size=8, patience=30, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=8, patience=30, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Missing {location}, epochs=200, batch_size=8, patience=30, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()   \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=8, patience=30, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=32, callbacks (patience=30), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=32, patience=30, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=32, patience=30, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=32, patience=30, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=32, patience=30, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=32, patience=30, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()    \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=32, patience=30, validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=8, callbacks (patience=50), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=8, patience=50, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=8, patience=50, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=8, patience=50, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=8, patience=50, validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=8, patience=50, validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()    \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=8, patience=50, validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=16, callbacks (patience=50), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "\n",
    "for location in range(0,12):\n",
    "    \n",
    "    filename = f'waterlevel_missing_{location}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for j, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = j\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "        first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of combine only (first):')                        #  \n",
    "        calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Mising {location}, epochs=200, batch_size=16, patience=50, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'64,128,256,200,200, Missing {location}, epochs=200, batch_size=16, patience=50, validation_split=0.2.png')\n",
    "        plt.show()\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_combine)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of combine only (last):')                       #\n",
    "        calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Mising {location}, epochs=200, batch_size=16, patience=50, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'64,128,256,200,200, Missing {location}, epochs=200, batch_size=16, patience=50, validation_split=0.2.png')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        model_MDa = model_combine(X_MDa_train)\n",
    "        model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        model_MDb = model_combine(X_MDb_train)\n",
    "        model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=16, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of combine only: ')                                         #\n",
    "        results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "        plt.title(f'Mising {location}, epochs=200, batch_size=16, patience=50, validation_split=0.2')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()    \n",
    "        plt.savefig(f'64,128,256,200,200, Missing {location}, epochs=200, batch_size=16, patience=50, validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "current_time = datetime.now()\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()    \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=32, callbacks (patience=50), validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=64, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=64, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=64, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=64, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()    \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=64, callbacks (patience=50), validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=128, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=128, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=128, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=128, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()    \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=128, callbacks (patience=50), validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# for location in range(0,12):\n",
    "    \n",
    "#     filename = f'waterlevel_missing_{location}.csv'\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     #### Check size of missing value\n",
    "#     size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "#     data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "#     nan_index = None\n",
    "#     for j, value in enumerate(data):\n",
    "#         if value != value:  # Check if the value is NaN\n",
    "#             nan_index = j\n",
    "#             break\n",
    "        \n",
    "#     df_check_before = data[:(3*size_of_gap)+1]\n",
    "#     df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "#     df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "#     last_data = data[:nan_index]\n",
    "#     first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "#     # check if missing values is in the first 3 x T data original\n",
    "#     if all(value in df_check_before for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the first !!!')\n",
    "\n",
    "#         first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=256, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_first_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "#         ###################################################################\n",
    "#         print('\\n', 'result of combine only (first):')                        #  \n",
    "#         calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "#         print('\\n')                                                       #\n",
    "#         ###################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_first_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     elif all(value in df_check_after for value in df_miss):\n",
    "#         print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "#         last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "#         df_list = to_df(last_value_combine)\n",
    "\n",
    "#         X = np.array(df_list.iloc[:, :-1])\n",
    "#         X = scaler.fit_transform(X)\n",
    "        \n",
    "#         y = np.array(df_list.iloc[:, -1])\n",
    "        \n",
    "#         model = model_combine(X)\n",
    "#         model.fit(X, y, epochs=200, batch_size=256, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "#         results_last_combine = []\n",
    "#         for i in range(len(data_test)//2):\n",
    "#             data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "#             data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "#         #################################################################\n",
    "#         print('\\n', 'result of combine only (last):')                       #\n",
    "#         calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "#         print('\\n')                                                     #\n",
    "#         # #################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_last_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2.png')\n",
    "#         plt.show()\n",
    "        \n",
    "#     else:\n",
    "#         Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "#         MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "#         df_MDa = to_df(MDa)\n",
    "\n",
    "#         X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "#         X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        \n",
    "#         y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "#         model_MDa = model_combine(X_MDa_train)\n",
    "#         model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=256, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "#         data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "#         data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "#         value_lst_after = []\n",
    "#         for j in range(len(data_test_after)//2):\n",
    "#             data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "#             data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "#             value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "#         Db = data[:nan_index]\n",
    "\n",
    "#         MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "#         df_MDb = to_df(MDb)\n",
    "\n",
    "#         X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "#         X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        \n",
    "#         y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "#         model_MDb = model_combine(X_MDb_train)\n",
    "#         model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=256, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "#         data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "#         data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "#         value_lst_before = []\n",
    "#         for i in range(len(data_test_before)//2):\n",
    "#             data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "#             data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "#             value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "#         #############################################################################\n",
    "#         print('\\n', 'result of combine only: ')                                         #\n",
    "#         results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "#         calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "#         print('\\n')                                                                 #\n",
    "#         #############################################################################\n",
    "        \n",
    "#         df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "#         plt.plot(results_combine, label='Predicted Value', linestyle='-')\n",
    "#         plt.title(f'Water Level vs Predicted Value, mising {location}, epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2')\n",
    "#         plt.xlabel('Index')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()    \n",
    "#         plt.savefig(f'Missing {location}, epochs=200, batch_size=256, callbacks (patience=50), validation_split=0.2.png')\n",
    "    \n",
    "    \n",
    "# current_time = datetime.now()\n",
    "\n",
    "# print('\\n')\n",
    "# print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "# print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "# print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "# print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "# print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "# print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "# print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
