{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dropout, Dense, Flatten, Attention, Layer, Concatenate, Permute, Reshape, Multiply\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "import warnings\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from pmdarima import auto_arima\n",
    "import keras.backend as K\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from lssvm import LSSVR\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(a,b,c,d,e,f,g):\n",
    "    current_time = datetime.now()\n",
    "    data = {\n",
    "        'model' : [g],\n",
    "        'sim' : [a],\n",
    "        'mae' : [b],\n",
    "        'rmse' : [c],\n",
    "        'fsd' : [d],\n",
    "        'R' : [e],\n",
    "        'NSE': [f],\n",
    "        'time' : [current_time]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    with open('results_combine.csv', 'a', newline='') as f:\n",
    "        if os.path.isfile('results_combine.csv'):\n",
    "            df.to_csv('results_combine.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv('results_combine.csv', index=False)\n",
    "\n",
    "def to_df(data_list):\n",
    "    X_df = [i[:-1] for i in data_list]\n",
    "    y_df = [i[-1] for i in data_list]\n",
    "    transposed_lists = [list(x) for x in zip(*X_df)]\n",
    "\n",
    "    df_list = pd.DataFrame({f'Column{i+1}': lst for i, lst in enumerate(transposed_lists)})\n",
    "    df_list['Target'] = y_df\n",
    "    return df_list\n",
    "\n",
    "def transform_to_multivariate(data, T):\n",
    "    M = []\n",
    "    for i in range(len(data) - T):\n",
    "        row = data[i:i + T + 1]\n",
    "        M.append(row)\n",
    "    return np.array(M)\n",
    "\n",
    "def calculate_similarity(value_lst_after, value_lst_before):\n",
    "        T = len(value_lst_after)  # Number of missing values\n",
    "        similarity_sum = 0\n",
    "\n",
    "        for i in range(T):\n",
    "            yi = value_lst_after[i]\n",
    "            xi = value_lst_before[i]\n",
    "            similarity_sum += 1 / (1 + abs(yi - xi) / (max(value_lst_before) - min(value_lst_before)))\n",
    "\n",
    "        similarity = similarity_sum / T\n",
    "        return similarity\n",
    "\n",
    "def calculate_MAE(value_lst_missing, value_lst_after):\n",
    "        return mean_absolute_error(value_lst_missing, value_lst_after)\n",
    "\n",
    "def calculate_RMSE(value_lst_missing, value_lst_after):\n",
    "    return np.sqrt(mean_squared_error(value_lst_missing, value_lst_after))\n",
    "\n",
    "def calculate_FB(value_lst_missing, value_lst_after):\n",
    "    return 2 * abs((np.mean(value_lst_after) - np.mean(value_lst_missing)) / (np.mean(value_lst_after) + np.mean(value_lst_missing)))\n",
    "\n",
    "def calculate_fsd(value_lst_missing, value_lst_after):\n",
    "    std_dev_Y = np.std(value_lst_after)\n",
    "    std_dev_X = np.std(value_lst_missing)\n",
    "\n",
    "    if std_dev_X == 0:\n",
    "        return None\n",
    "    \n",
    "    fsd = 2 * abs((std_dev_Y - std_dev_X) / (std_dev_X + std_dev_Y))\n",
    "    \n",
    "    return fsd\n",
    "\n",
    "def calculate_r_score(value_lst_missing, value_lst_after):\n",
    "\n",
    "    correlation_matrix = np.corrcoef(value_lst_missing, value_lst_after)\n",
    "    r_score = correlation_matrix[0, 1]\n",
    "    return r_score\n",
    "\n",
    "def calculate_nse(value_lst_missing, value_lst_after):\n",
    "\n",
    "    value_lst_missing = np.array(value_lst_missing)\n",
    "    value_lst_after = np.array(value_lst_after)\n",
    "\n",
    "    numerator = np.sum((value_lst_missing - value_lst_after)**2)\n",
    "    denominator = np.sum((value_lst_missing - np.mean(value_lst_missing))**2)\n",
    "\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    \n",
    "    return nse\n",
    "\n",
    "\n",
    "def calculate_metrics_for_combine(value_lst_after,name_model):\n",
    "    \n",
    "    df_before_missing = pd.read_csv('waterlevel.csv')\n",
    "    value_lst_missing = df_before_missing['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap]\n",
    "\n",
    "\n",
    "    similarity_score = calculate_similarity(value_lst_after, value_lst_missing)\n",
    "    MAE_score = calculate_MAE(value_lst_missing, value_lst_after)\n",
    "    RMSE_score = calculate_RMSE(value_lst_missing, value_lst_after)\n",
    "    FSD_score = calculate_fsd(value_lst_missing, value_lst_after)\n",
    "    R_score = calculate_r_score(value_lst_missing, value_lst_after)\n",
    "    NSE_score = calculate_nse(value_lst_missing, value_lst_after)\n",
    "    \n",
    "    sim_lst_combine.append(similarity_score)\n",
    "    mae_lst_combine.append(MAE_score)\n",
    "    rmse_lst_combine.append(RMSE_score)\n",
    "    fsd_lst_combine.append(FSD_score)\n",
    "    r_lst_combine.append(R_score)\n",
    "    nse_lst_combine.append(NSE_score)\n",
    "\n",
    "    \n",
    "    print('\\nOri_data:', value_lst_missing)\n",
    "    print('\\nvalue_data:', value_lst_after)\n",
    "    print('\\nSimilarity_score:', similarity_score)\n",
    "    print('\\nMean Absolute Error (MAE):', MAE_score)\n",
    "    print('\\nRoot Mean Squared Error (RMSE):', RMSE_score)\n",
    "    print('\\nFraction of Standard Deviation Score:', FSD_score)\n",
    "    print('\\nR score:', R_score)\n",
    "    print('\\nThe Nash Sutcliffe efficiency (NSE):', NSE_score)\n",
    "\n",
    "    results(similarity_score, MAE_score, RMSE_score, FSD_score, R_score, NSE_score,name_model)\n",
    "    \n",
    "def calculate_metrics_for_LSSVM(value_lst_after,name_model):\n",
    "    \n",
    "    df_before_missing = pd.read_csv('waterlevel.csv')\n",
    "    value_lst_missing = df_before_missing['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap]\n",
    "\n",
    "\n",
    "    similarity_score = calculate_similarity(value_lst_after, value_lst_missing)\n",
    "    MAE_score = calculate_MAE(value_lst_missing, value_lst_after)\n",
    "    RMSE_score = calculate_RMSE(value_lst_missing, value_lst_after)\n",
    "    FSD_score = calculate_fsd(value_lst_missing, value_lst_after)\n",
    "    R_score = calculate_r_score(value_lst_missing, value_lst_after)\n",
    "    NSE_score = calculate_nse(value_lst_missing, value_lst_after)\n",
    "    \n",
    "    sim_lst_LSSVM.append(similarity_score)\n",
    "    mae_lst_LSSVM.append(MAE_score)\n",
    "    rmse_lst_LSSVM.append(RMSE_score)\n",
    "    fsd_lst_LSSVM.append(FSD_score)\n",
    "    r_lst_LSSVM.append(R_score)\n",
    "    nse_lst_LSSVM.append(NSE_score)\n",
    "\n",
    "    \n",
    "    print('\\nOri_data:', value_lst_missing)\n",
    "    print('\\nvalue_data:', value_lst_after)\n",
    "    print('\\nSimilarity_score:', similarity_score)\n",
    "    print('\\nMean Absolute Error (MAE):', MAE_score)\n",
    "    print('\\nRoot Mean Squared Error (RMSE):', RMSE_score)\n",
    "    print('\\nFraction of Standard Deviation Score:', FSD_score)\n",
    "    print('\\nR score:', R_score)\n",
    "    print('\\nThe Nash Sutcliffe efficiency (NSE):', NSE_score)\n",
    "\n",
    "    results(similarity_score, MAE_score, RMSE_score, FSD_score, R_score, NSE_score,name_model)\n",
    "    \n",
    "def calculate_metrics_for_Bi_LSTM(value_lst_after,name_model):\n",
    "    \n",
    "    df_before_missing = pd.read_csv('waterlevel.csv')\n",
    "    value_lst_missing = df_before_missing['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap]\n",
    "\n",
    "\n",
    "    similarity_score = calculate_similarity(value_lst_after, value_lst_missing)\n",
    "    MAE_score = calculate_MAE(value_lst_missing, value_lst_after)\n",
    "    RMSE_score = calculate_RMSE(value_lst_missing, value_lst_after)\n",
    "    FSD_score = calculate_fsd(value_lst_missing, value_lst_after)\n",
    "    R_score = calculate_r_score(value_lst_missing, value_lst_after)\n",
    "    NSE_score = calculate_nse(value_lst_missing, value_lst_after)\n",
    "    \n",
    "    sim_lst_Bi_LSTM.append(similarity_score)\n",
    "    mae_lst_Bi_LSTM.append(MAE_score)\n",
    "    rmse_lst_Bi_LSTM.append(RMSE_score)\n",
    "    fsd_lst_Bi_LSTM.append(FSD_score)\n",
    "    r_lst_Bi_LSTM.append(R_score)\n",
    "    nse_lst_Bi_LSTM.append(NSE_score)\n",
    "\n",
    "    \n",
    "    print('\\nOri_data:', value_lst_missing)\n",
    "    print('\\nvalue_data:', value_lst_after)\n",
    "    print('\\nSimilarity_score:', similarity_score)\n",
    "    print('\\nMean Absolute Error (MAE):', MAE_score)\n",
    "    print('\\nRoot Mean Squared Error (RMSE):', RMSE_score)\n",
    "    print('\\nFraction of Standard Deviation Score:', FSD_score)\n",
    "    print('\\nR score:', R_score)\n",
    "    print('\\nThe Nash Sutcliffe efficiency (NSE):', NSE_score)\n",
    "\n",
    "    results(similarity_score, MAE_score, RMSE_score, FSD_score, R_score, NSE_score,name_model)\n",
    "    \n",
    "def calculate_metrics_for_CNN(value_lst_after,name_model):\n",
    "    \n",
    "    df_before_missing = pd.read_csv('waterlevel.csv')\n",
    "    value_lst_missing = df_before_missing['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap]\n",
    "\n",
    "\n",
    "    similarity_score = calculate_similarity(value_lst_after, value_lst_missing)\n",
    "    MAE_score = calculate_MAE(value_lst_missing, value_lst_after)\n",
    "    RMSE_score = calculate_RMSE(value_lst_missing, value_lst_after)\n",
    "    FSD_score = calculate_fsd(value_lst_missing, value_lst_after)\n",
    "    R_score = calculate_r_score(value_lst_missing, value_lst_after)\n",
    "    NSE_score = calculate_nse(value_lst_missing, value_lst_after)\n",
    "    \n",
    "    sim_lst_CNN.append(similarity_score)\n",
    "    mae_lst_CNN.append(MAE_score)\n",
    "    rmse_lst_CNN.append(RMSE_score)\n",
    "    fsd_lst_CNN.append(FSD_score)\n",
    "    r_lst_CNN.append(R_score)\n",
    "    nse_lst_CNN.append(NSE_score)\n",
    "\n",
    "    \n",
    "    print('\\nOri_data:', value_lst_missing)\n",
    "    print('\\nvalue_data:', value_lst_after)\n",
    "    print('\\nSimilarity_score:', similarity_score)\n",
    "    print('\\nMean Absolute Error (MAE):', MAE_score)\n",
    "    print('\\nRoot Mean Squared Error (RMSE):', RMSE_score)\n",
    "    print('\\nFraction of Standard Deviation Score:', FSD_score)\n",
    "    print('\\nR score:', R_score)\n",
    "    print('\\nThe Nash Sutcliffe efficiency (NSE):', NSE_score)\n",
    "\n",
    "    results(similarity_score, MAE_score, RMSE_score, FSD_score, R_score, NSE_score,name_model)\n",
    "\n",
    "\n",
    "def create_continuous_missing_values(dataframe, column_name, num_missing_values):\n",
    "    modified_df = dataframe.copy()\n",
    "    \n",
    "    if len(dataframe) > num_missing_values:\n",
    "        random_index = random.randint(0, len(dataframe) - num_missing_values)\n",
    "        modified_df.loc[random_index:random_index + num_missing_values - 1, column_name] = np.nan\n",
    "    else:\n",
    "        print(\"Error: The number of missing values requested exceeds the DataFrame's capacity.\")\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "sim_lst_combine = []\n",
    "mae_lst_combine = []\n",
    "rmse_lst_combine = []\n",
    "fsd_lst_combine = []\n",
    "r_lst_combine = []\n",
    "nse_lst_combine = []\n",
    "\n",
    "sim_lst_CNN = []\n",
    "mae_lst_CNN = []\n",
    "rmse_lst_CNN = []\n",
    "fsd_lst_CNN = []\n",
    "r_lst_CNN = []\n",
    "nse_lst_CNN = []\n",
    "\n",
    "sim_lst_Bi_LSTM = []\n",
    "mae_lst_Bi_LSTM = []\n",
    "rmse_lst_Bi_LSTM = []\n",
    "fsd_lst_Bi_LSTM = []\n",
    "r_lst_Bi_LSTM = []\n",
    "nse_lst_Bi_LSTM = []\n",
    "\n",
    "sim_lst_LSSVM = []\n",
    "mae_lst_LSSVM = []\n",
    "rmse_lst_LSSVM = []\n",
    "fsd_lst_LSSVM = []\n",
    "r_lst_LSSVM = []\n",
    "nse_lst_LSSVM = []\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_df_path = 'waterlevel.csv'\n",
    "# try:\n",
    "#     original_df = pd.read_csv(original_df_path)\n",
    "    \n",
    "#     for i in range(5,6):\n",
    "#         modified_df = create_continuous_missing_values(original_df, 'Waterlevel', 48)\n",
    "#         modified_df.to_csv(f'waterlevel_missing_{i}.csv', index=False)\n",
    "        \n",
    "#         print(f'waterlevel_missing_{i}.csv saved with continuous missing values.')\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Failed to find '{original_df_path}'. Please check the file path and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_combine(X_train):\n",
    "    combine = tf.keras.models.Sequential()\n",
    "    combine.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    combine.add(MaxPooling1D(pool_size=2))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    combine.add(Bidirectional(LSTM(units=200, return_sequences=True)))\n",
    "    combine.add(Dropout(0.15))\n",
    "    \n",
    "    class Attention(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            super(Attention, self).__init__(**kwargs)\n",
    "    \n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1), \n",
    "                                     initializer='random_normal', trainable=True)\n",
    "            self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1), \n",
    "                                     initializer='zeros', trainable=True)        \n",
    "            super(Attention, self).build(input_shape)\n",
    "     \n",
    "        def call(self, x):\n",
    "            e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "            e = K.squeeze(e, axis=-1)\n",
    "            alpha = K.softmax(e)\n",
    "            alpha = K.expand_dims(alpha, axis=-1)\n",
    "            context = x * alpha\n",
    "            context = K.sum(context, axis=1)\n",
    "            return context\n",
    "\n",
    "    combine.add(Attention())\n",
    "    \n",
    "    combine.add(Dense(units=200, activation='relu'))\n",
    "    \n",
    "    combine.add(Dense(units=1))\n",
    "    \n",
    "    combine.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for i in range(0, 1):\n",
    "    \n",
    "    filename = f'waterlevel_missing_{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for i, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = i\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "        \n",
    "        # Calculate for combine \n",
    "        first_value_combine = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_combine)\n",
    "        \n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_combine(X)        \n",
    "        # model.fit(X, y, epochs=2000, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_combine.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of combine only (first):')                        #  \n",
    "        calculate_metrics_for_combine(results_first_combine,'results_combine (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_combine, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_combine = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_combine)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_combine(X)\n",
    "        # model.fit(X, y, epochs=2000, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        model = model_combine(X)\n",
    "        model.fit(X, y, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_combine = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            # data_last[size_of_gap] = float(model.predict(np.array(data_last[:size_of_gap]).reshape(1,-1)).ravel()[0])\n",
    "            data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_combine.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of combine only (last):')                       #\n",
    "        calculate_metrics_for_combine(results_last_combine,'results_combine (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_combine, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        # X_MDa_train = X_MDa_train.reshape((X_MDa_train.shape[0], X_MDa_train.shape[1], 1))\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        # model_MDa, callbacks_MDa = model_combine(X_MDa_train)\n",
    "        # model_MDa.fit(X_MDa_train, y_MDa_train, epochs=2000, batch_size = 64, callbacks=callbacks_MDa)\n",
    "        \n",
    "        model_MDa = model_combine(X_MDa_train)\n",
    "        model_MDa.fit(X_MDa_train, y_MDa_train, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        # X_MDb_train = X_MDb_train.reshape((X_MDb_train.shape[0], X_MDb_train.shape[1], 1))\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        # model_MDb, callbacks_MDb = model_combine(X_MDb_train)\n",
    "        # model_MDb.fit(X_MDb_train, y_MDb_train, epochs=2000, batch_size = 64, callbacks=callbacks_MDb)\n",
    "        \n",
    "        model_MDb = model_combine(X_MDb_train)\n",
    "        model_MDb.fit(X_MDb_train, y_MDb_train, epochs=200, batch_size=8, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of combine only: ')                                         #\n",
    "        results_combine =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_combine(results_combine,'results_combine (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_combine, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "      \n",
    "current_time = datetime.now()\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity combine: ',np.mean(sim_lst_combine))\n",
    "print('\\nMean of Mean Absoulute Error combine :',np.mean(mae_lst_combine))\n",
    "print('\\nMean of Root Mean Squared Error combine: ',np.mean(rmse_lst_combine))\n",
    "print('\\nMean of Fraction of Standard Deviation combine: ',np.mean(fsd_lst_combine)) \n",
    "print('\\nMean of R-score combine: ', np.mean(r_lst_combine))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_combine))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Bi_LSTM(X_train):\n",
    "    bi_lstm = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "    bi_lstm.add(Bidirectional(LSTM(units=200, return_sequences=True), input_shape=(X_train.shape[1], 1)))\n",
    "    bi_lstm.add(Dropout(0.15))\n",
    "    \n",
    "    bi_lstm.add(LSTM(units=200, return_sequences=True))\n",
    "    bi_lstm.add(Dropout(0.15))\n",
    "    bi_lstm.add(LSTM(units=200, return_sequences=True))\n",
    "    bi_lstm.add(Dropout(0.15))\n",
    "    bi_lstm.add(LSTM(units=200))\n",
    "    bi_lstm.add(Dropout(0.15))\n",
    "    \n",
    "    bi_lstm.add(Dense(units=200, activation = \"relu\"))\n",
    "    bi_lstm.add(Dense(units=1))\n",
    "    \n",
    "    \n",
    "    bi_lstm.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return bi_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "for i in range(0, 12):\n",
    "    \n",
    "    filename = f'waterlevel_missing_{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for i, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = i\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "        \n",
    "        # Calculate for Bi_LSTM \n",
    "        first_value_Bi_LSTM = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_Bi_LSTM)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_Bi_LSTM(X)        \n",
    "        # model.fit(X, y, epochs=500, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        model = model_Bi_LSTM(X)\n",
    "        model.fit(X, y, epochs=50, batch_size=64)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_Bi_LSTM = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_Bi_LSTM.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of Bi_LSTM only (first):')                        #  \n",
    "        calculate_metrics_for_Bi_LSTM(results_first_Bi_LSTM,'results_Bi_LSTM (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_Bi_LSTM, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_Bi_LSTM = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_Bi_LSTM)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_Bi_LSTM(X)\n",
    "        # model.fit(X, y, epochs=500, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        model = model_Bi_LSTM(X)\n",
    "        model.fit(X, y, epochs=50, batch_size=64)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_Bi_LSTM = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            # data_last[size_of_gap] = float(model.predict(np.array(data_last[:size_of_gap]).reshape(1,-1)).ravel()[0])\n",
    "            data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_Bi_LSTM.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of Bi_LSTM only (last):')                       #\n",
    "        calculate_metrics_for_Bi_LSTM(results_last_Bi_LSTM,'results_Bi_LSTM (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_Bi_LSTM, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        # X_MDa_train = X_MDa_train.reshape((X_MDa_train.shape[0], X_MDa_train.shape[1], 1))\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        # model_MDa, callbacks_MDa = model_Bi_LSTM(X_MDa_train)\n",
    "        # model_MDa.fit(X_MDa_train, y_MDa_train, epochs=500, batch_size = 64, callbacks=callbacks_MDa)\n",
    "        \n",
    "        model_MDa = model_Bi_LSTM(X_MDa_train)\n",
    "        model_MDa.fit(X_MDa_train, y_MDa_train, epochs=50, batch_size=64)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        # X_MDb_train = X_MDb_train.reshape((X_MDb_train.shape[0], X_MDb_train.shape[1], 1))\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        # model_MDb, callbacks_MDb = model_Bi_LSTM(X_MDb_train)\n",
    "        # model_MDb.fit(X_MDb_train, y_MDb_train, epochs=500, batch_size = 64, callbacks=callbacks_MDb)\n",
    "        \n",
    "        model_MDb = model_Bi_LSTM(X_MDb_train)\n",
    "        model_MDb.fit(X_MDb_train, y_MDb_train, epochs=50, batch_size=64)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of Bi_LSTM only: ')                                         #\n",
    "        results_Bi_LSTM =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_Bi_LSTM(results_Bi_LSTM,'results_Bi_LSTM (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_Bi_LSTM, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "current_time = datetime.now()\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity Bi_LSTM: ',np.mean(sim_lst_Bi_LSTM))\n",
    "print('\\nMean of Mean Absoulute Error Bi_LSTM :',np.mean(mae_lst_Bi_LSTM))\n",
    "print('\\nMean of Root Mean Squared Error Bi_LSTM: ',np.mean(rmse_lst_Bi_LSTM))\n",
    "print('\\nMean of Fraction of Standard Deviation Bi_LSTM: ',np.mean(fsd_lst_Bi_LSTM)) \n",
    "print('\\nMean of R-score Bi_LSTM: ', np.mean(r_lst_Bi_LSTM))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_Bi_LSTM))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_CNN(X_train):\n",
    "    \n",
    "    CNN = tf.keras.models.Sequential()\n",
    "    CNN.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    CNN.add(MaxPooling1D(pool_size=2))\n",
    "    CNN.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    CNN.add(Dropout(0.15))\n",
    "    CNN.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "    CNN.add(Dropout(0.15))\n",
    "    CNN.add(Flatten())\n",
    "    CNN.add(Dense(50, activation='relu'))\n",
    "    CNN.add(Dropout(0.2))\n",
    "    \n",
    "    CNN.add(Dense(units=1))\n",
    "    \n",
    "    CNN.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['mae'])\n",
    "    \n",
    "    return CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "for i in range(0,12):\n",
    "    \n",
    "    filename = f'waterlevel_missing_{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    #### Check size of missing value\n",
    "    size_of_gap = df['Waterlevel'].isna().sum()\n",
    "\n",
    "    data = df['Waterlevel'].values.tolist()\n",
    "\n",
    "    nan_index = None\n",
    "    for i, value in enumerate(data):\n",
    "        if value != value:  # Check if the value is NaN\n",
    "            nan_index = i\n",
    "            break\n",
    "        \n",
    "    df_check_before = data[:(3*size_of_gap)+1]\n",
    "    df_check_after = data[::-1][:3*size_of_gap+1]\n",
    "    df_miss = data[nan_index:nan_index + size_of_gap]\n",
    "\n",
    "    last_data = data[:nan_index]\n",
    "    first_data = data[nan_index+size_of_gap:][::-1]\n",
    "\n",
    "    # check if missing values is in the first 3 x T data original\n",
    "    if all(value in df_check_before for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the first !!!')\n",
    "        \n",
    "        # Calculate for CNN \n",
    "        first_value_CNN = transform_to_multivariate(first_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(first_value_CNN)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_CNN(X)        \n",
    "        # model.fit(X, y, epochs=500, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        model = model_CNN(X)\n",
    "        model.fit(X, y, epochs=50, batch_size=16)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index : nan_index + 2 * size_of_gap][::-1]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_first_CNN = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_first = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            data_first[size_of_gap] = model.predict(scaler.transform(np.array(data_first[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_first_CNN.append(data_first[size_of_gap])\n",
    "            \n",
    "        ###################################################################\n",
    "        print('\\n', 'result of CNN only (first):')                        #  \n",
    "        calculate_metrics_for_CNN(results_first_CNN,'results_CNN (FIRST)')#\n",
    "        print('\\n')                                                       #\n",
    "        ###################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_first_CNN, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif all(value in df_check_after for value in df_miss):\n",
    "        print('\\nAll values in df_miss is in the last !!!')\n",
    "        \n",
    "        last_value_CNN = transform_to_multivariate(last_data, size_of_gap)\n",
    "                \n",
    "        df_list = to_df(last_value_CNN)\n",
    "\n",
    "        X = np.array(df_list.iloc[:, :-1])\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        y = np.array(df_list.iloc[:, -1])\n",
    "\n",
    "        # model, callbacks = model_CNN(X)\n",
    "        # model.fit(X, y, epochs=500, batch_size = 64, callbacks=callbacks)\n",
    "        \n",
    "        model = model_CNN(X)\n",
    "        model.fit(X, y, epochs=50, batch_size=16)\n",
    "\n",
    "        data_test = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test = np.concatenate(data_test).ravel()   \n",
    "\n",
    "        results_last_CNN = []\n",
    "        for i in range(len(data_test)//2):\n",
    "            data_last = data_test[i:i+1+size_of_gap]\n",
    "\n",
    "            # data_last[size_of_gap] = float(model.predict(np.array(data_last[:size_of_gap]).reshape(1,-1)).ravel()[0])\n",
    "            data_last[size_of_gap] = model.predict(scaler.transform(np.array(data_last[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            results_last_CNN.append(data_last[size_of_gap])\n",
    "            \n",
    "        #################################################################\n",
    "        print('\\n', 'result of CNN only (last):')                       #\n",
    "        calculate_metrics_for_CNN(results_last_CNN,'results_CNN (LAST)')#\n",
    "        print('\\n')                                                     #\n",
    "        # #################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_last_CNN, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        Da = data[nan_index + size_of_gap:][::-1]\n",
    "\n",
    "        MDa = transform_to_multivariate(Da, size_of_gap)\n",
    "\n",
    "        df_MDa = to_df(MDa)\n",
    "\n",
    "        X_MDa_train = np.array(df_MDa.iloc[:, :-1])\n",
    "        X_MDa_train = scaler.fit_transform(X_MDa_train)\n",
    "        # X_MDa_train = X_MDa_train.reshape((X_MDa_train.shape[0], X_MDa_train.shape[1], 1))\n",
    "        \n",
    "        y_MDa_train = np.array(df_MDa.iloc[:, -1])\n",
    "\n",
    "        # model_MDa, callbacks_MDa = model_CNN(X_MDa_train)\n",
    "        # model_MDa.fit(X_MDa_train, y_MDa_train, epochs=500, batch_size = 64, callbacks=callbacks_MDa)\n",
    "        \n",
    "        model_MDa = model_CNN(X_MDa_train)\n",
    "        model_MDa.fit(X_MDa_train, y_MDa_train, epochs=50, batch_size=16)\n",
    "        \n",
    "        data_test_after = df.values.tolist()[nan_index:nan_index + 2 * size_of_gap ][::-1]\n",
    "        data_test_after = np.concatenate(data_test_after).ravel()   \n",
    "\n",
    "        value_lst_after = []\n",
    "        for j in range(len(data_test_after)//2):\n",
    "            data_after = data_test_after[j:j+1+size_of_gap]\n",
    "            \n",
    "            data_after[size_of_gap] = model_MDa.predict(scaler.transform(np.array(data_after[:size_of_gap]).reshape(1,-1)))\n",
    "            \n",
    "            value_lst_after.append(data_after[size_of_gap])\n",
    "\n",
    "        Db = data[:nan_index]\n",
    "\n",
    "        MDb = transform_to_multivariate(Db, size_of_gap)  \n",
    "\n",
    "        df_MDb = to_df(MDb)\n",
    "\n",
    "        X_MDb_train = np.array(df_MDb.iloc[:, :-1])\n",
    "        X_MDb_train = scaler.fit_transform(X_MDb_train)\n",
    "        # X_MDb_train = X_MDb_train.reshape((X_MDb_train.shape[0], X_MDb_train.shape[1], 1))\n",
    "        \n",
    "        y_MDb_train = np.array(df_MDb.iloc[:, -1])\n",
    "\n",
    "        # model_MDb, callbacks_MDb = model_CNN(X_MDb_train)\n",
    "        # model_MDb.fit(X_MDb_train, y_MDb_train, epochs=500, batch_size = 64, callbacks=callbacks_MDb)\n",
    "        \n",
    "        model_MDb = model_CNN(X_MDb_train)\n",
    "        model_MDb.fit(X_MDb_train, y_MDb_train, epochs=50, batch_size=16)\n",
    "\n",
    "        data_test_before = df.values.tolist()[nan_index - size_of_gap : nan_index + size_of_gap]\n",
    "        data_test_before = np.concatenate(data_test_before).ravel()   \n",
    "\n",
    "        value_lst_before = []\n",
    "        for i in range(len(data_test_before)//2):\n",
    "            data_before = data_test_before[i:i+1+size_of_gap]\n",
    "            \n",
    "            data_before[size_of_gap] = model_MDb.predict(scaler.transform(np.array(data_before[:size_of_gap]).reshape(1,-1)))\n",
    "\n",
    "            value_lst_before.append(data_before[size_of_gap])\n",
    "\n",
    "        #############################################################################\n",
    "        print('\\n', 'result of CNN only: ')                                         #\n",
    "        results_CNN =  [(x + y)/2 for x,y in zip(value_lst_before, value_lst_after)]#\n",
    "        calculate_metrics_for_CNN(results_CNN,'results_CNN (MIDDLE)')               #\n",
    "        print('\\n')                                                                 #\n",
    "        #############################################################################\n",
    "        \n",
    "        df = pd.read_csv('Impute_misvalues_hungyen.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['Waterlevel'].values.tolist()[nan_index:nan_index+size_of_gap], label='Water Level')\n",
    "        plt.plot(results_CNN, label='Predicted Value', linestyle='--')\n",
    "        plt.title('Water Level vs Predicted Value Over Time')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "current_time = datetime.now()\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('\\nMean of Similarity CNN: ',np.mean(sim_lst_CNN))\n",
    "print('\\nMean of Mean Absoulute Error CNN :',np.mean(mae_lst_CNN))\n",
    "print('\\nMean of Root Mean Squared Error CNN: ',np.mean(rmse_lst_CNN))\n",
    "print('\\nMean of Fraction of Standard Deviation CNN: ',np.mean(fsd_lst_CNN)) \n",
    "print('\\nMean of R-score CNN: ', np.mean(r_lst_CNN))\n",
    "print('\\nMean of the Nash Sutcliffe efficiency (NSE): ', np.mean(nse_lst_CNN))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
